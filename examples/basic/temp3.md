yarn dev
yarn run v1.22.22
$ tsx examples/basic/simple-research.ts
Starting deep research...
[Step 1] Generating research plan... at 1
expected output tokens: 1500
[Step 2] Running initial web searches with 3 queries...
Received 3 initial search results
[Step 2.5] Deduplicating search results...
[Step 3] Reasoning about the search results...
[Step 4] Decision making...
[Step 1] Generating research plan... at 2
expected output tokens: 6000
[Step 2] Running initial web searches with 5 queries...
Received 5 initial search results
[Step 2.5] Deduplicating search results...
[Step 3] Reasoning about the search results...
[Step 4] Decision making...
[Step 1] Generating research plan... at 3
expected output tokens: 6000
[Step 2] Running initial web searches with 7 queries...
Received 7 initial search results
[Step 2.5] Deduplicating search results...
[Step 3] Reasoning about the search results...
[Step 4] Decision making...
[Step 5] Generating report...
[Iteration 0] phase=initial
[Iteration 1] phase=continuation
[Iteration 2] phase=continuation
[Iteration 3] phase=continuation
[Iteration 4] phase=continuation
[Iteration 5] phase=continuation
[Iteration 6] phase=continuation
[Iteration 7] phase=continuation
[Iteration 8] phase=continuation
[Iteration 9] phase=continuation
Reference map size: 137
Generating bibliography with 137 entries
Done processing report for sources

== 

result The PAROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) through complex visual reasoning tasks [[1](https://arxiv.org/abs/2411.15201)][[37](https://www.scribd.com/document/365556123/datasheet-fgd4536)]. It includes 2,487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet and test VLMs on real-world problem-solving scenarios [[5](https://github.com/jamycheung/360BEV/blob/main/README.md), [6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving), [103](https://github.com/AIDC-AI/Parrot/blob/main/README.md)]. The benchmark assesses the ability of VLMs to process visual and textual information to solve sequential tasks [[82](https://arxiv.org/html/2407.14066v2)]. The PAROT-360V dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology involves evaluating VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. The benchmark is designed to evaluate and enhance VLMs for applications like autonomous driving and robotics [[8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2,487 visual puzzles designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are scraped from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The benchmark methodology evaluates VLMs in complex, real-world problem-solving scenarios [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving), [71](https://www.intel.com/content/www/us/en/docs/mpi-library/user-guide-benchmarks/2021-8/benchmark-methodology.html)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)]. The benchmark uses jumble puzzles to test VLMs on real-world problem-solving scenarios [[5](https://github.com/jamycheung/360BEV/blob/main/README.md), [6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving), [103](https://github.com/AIDC-AI/Parrot/blob/main/README.md)]. The PAROT-360V benchmark is a novel tool for evaluating VLMs by assessing their ability to process complex visual and textual information [[82](https://arxiv.org/html/2407.14066v2)]. The methodology involves evaluating VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. The PAROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) on complex visual reasoning tasks that mirror real-world challenges [[1](https://arxiv.org/abs/2411.15201), [15](https://arxiv.org/html/2407.14066v3)].The PAROT-360V benchmark includes 2487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2,487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2,487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2487 challenging visual puzzles designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2,487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2,487 challenging visual puzzles [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. The puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].The PAROT-360V benchmark includes 2,487 challenging visual puzzles designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are sourced from the internet [[5](https://github.com/jamycheung/360BEV/blob/main/README.md)]. The PARROT-360V benchmark dataset is composed of visual puzzles [[102](https://play.google.com/store/apps/details?id=com.sparted.groupeparot&amp%3Bhl=en_US)]. The methodology is designed to evaluate VLMs on multi-step reasoning tasks [[11](https://about.parot.nz/features/ncea-analysis), [80](https://artificialanalysis.ai/methodology/performance-benchmarking)]. PAROT-360V assesses VLMs' ability to process visual and textual information to solve sequential tasks [[1](https://arxiv.org/abs/2411.15201), [82](https://arxiv.org/html/2407.14066v2)]. It is designed to evaluate and enhance VLMs for real-world applications such as autonomous driving and robotics [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [8](https://www.tvtechnology.com/news/parrot-analytics-launches-global-streaming-metrics), [89](https://www.techradar.com/best/best-benchmarks-software)].
✨  Done in 205.18s.