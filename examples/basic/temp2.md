yarn dev
yarn run v1.22.22
$ tsx examples/basic/simple-research.ts
Starting deep research...
[Step 1] Generating research plan... at 1
expected output tokens: 1500
[Step 2] Running initial web searches with 3 queries...
Received 3 initial search results
[Step 2.5] Deduplicating search results...
[Step 3] Reasoning about the search results...
[Step 4] Decision making...
[Step 1] Generating research plan... at 2
expected output tokens: 6000
[Step 2] Running initial web searches with 5 queries...
Received 5 initial search results
[Step 2.5] Deduplicating search results...
[Step 3] Reasoning about the search results...
[Step 4] Decision making...
[Step 1] Generating research plan... at 3
expected output tokens: 6000
[Step 2] Running initial web searches with 3 queries...
Received 3 initial search results
[Step 2.5] Deduplicating search results...
[Step 3] Reasoning about the search results...
[Step 4] Decision making...
[Step 5] Generating report...
[Iteration 0] phase=initial
[Iteration 1] phase=continuation
[Iteration 2] phase=continuation
[Iteration 3] phase=continuation
[Iteration 4] phase=continuation
[Iteration 5] phase=continuation
[Iteration 6] phase=continuation
[Iteration 7] phase=continuation
Reference map size: 142
Generating bibliography with 142 entries
Done processing report for sources


-
result The PARROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) using complex, sequential puzzles that reflect real-world challenges [[1](https://arxiv.org/abs/2411.15201)][[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving)]. The benchmark includes 2,487 visual puzzles designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are scraped to form the dataset [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)].The PARROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) using complex, sequential puzzles that reflect real-world challenges [[1](https://arxiv.org/abs/2411.15201)][[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving)]. The benchmark includes 2,487 visual puzzles designed to test VLMs on complex visual reasoning tasks [[2](https://arxiv.org/html/2411.15201v1), [52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are scraped to form the dataset [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V dataset includes 2487 challenging visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. A sample puzzle is included in the benchmark [[52](https://www.cpubenchmark.net/graph_notes.html)].The PARROT-360V benchmark is a tool designed to evaluate the capabilities of Vision Language Models (VLMs) in complex visual reasoning [[37](https://dl.acm.org/doi/10.1609/aaai.v37i3.25450)]. The PARROT-360V benchmark dataset includes 2487 challenging visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are jumbled to create the dataset [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. The PARROT-360V benchmark is a novel evaluation tool for Vision Language Models (VLMs) that emphasizes complex, multi-step reasoning with visual and textual elements [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving)]. The primary source for information about PARROT-360V is an academic paper hosted on arXiv [[95](https://www.antekinc.com/as-4t360-400va-360v-transformer/)]. The title of the paper is "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[2](https://arxiv.org/html/2411.15201v1)].The PARROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) on complex, sequential puzzles that mirror real-world challenges [[1](https://arxiv.org/abs/2411.15201)]. The PARROT-360V dataset includes 2,487 visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are sourced from jumbled puzzles [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. The PARROT-360V benchmark is a novel evaluation tool for Vision Language Models (VLMs) that emphasizes complex, multi-step reasoning with visual and textual elements [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving)]. The primary source for information about PARROT-360V is an academic paper hosted on arXiv [[95](https://www.antekinc.com/as-4t360-400va-360v-transformer/)]. The title of the paper is "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[2](https://arxiv.org/html/2411.15201v1)]. The PARROT-360V benchmark is a tool designed to evaluate the capabilities of Vision Language Models (VLMs) in complex visual reasoning [[37](https://dl.acm.org/doi/10.1609/aaai.v37i3.25450)].The PARROT-360V benchmark is designed to assess Vision Language Models (VLMs) using intricate, sequential puzzles that are similar to real-world scenarios [[1](https://arxiv.org/abs/2411.15201)]. The benchmark incorporates 2,487 visual puzzles to evaluate VLMs on visual reasoning tasks [[52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are derived from jumbled puzzles [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The primary source for the PARROT-360V benchmark is an academic paper available on arXiv, titled "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[1](https://arxiv.org/abs/2411.15201), [2](https://arxiv.org/html/2411.15201v1)]. PARROT-360V evaluates VLMs through complex, sequential puzzles that emulate real-world challenges [[4](https://www.redblock.ai/resources/blog/parrot-360v-elevating-vision-language-model-evaluation-through-real-world-problem-solving), [11](https://about.parot.nz/features/ncea-analysis)]. The dataset comprises 2,487 visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)].

The PARROT-360V benchmark is a tool for assessing the capabilities of Vision Language Models (VLMs) in complex visual reasoning [[37](https://dl.acm.org/doi/10.1609/aaai.v37i3.25450)]. The PARROT-360V dataset includes 2487 challenging visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are jumbled to create the dataset [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. The PARROT-360V benchmark is a novel evaluation tool for Vision Language Models (VLMs) that emphasizes complex, multi-step reasoning with visual and textual elements [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving)]. The primary source for information about PARROT-360V is an academic paper hosted on arXiv [[95](https://www.antekinc.com/as-4t360-400va-360v-transformer/)]. The title of the paper is "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[2](https://arxiv.org/html/2411.15201v1)].The PARROT-360V benchmark includes 2,487 visual puzzles specifically designed to evaluate VLMs on their capacity for complex visual reasoning [[52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are sourced from jumbled puzzles [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark is a tool designed to evaluate the capabilities of Vision Language Models (VLMs) in complex visual reasoning [[37](https://dl.acm.org/doi/10.1609/aaai.v37i3.25450)]. The PARROT-360V benchmark dataset includes 2487 challenging visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are jumbled to create the dataset [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. The PARROT-360V benchmark is a novel evaluation tool for Vision Language Models (VLMs) that emphasizes complex, multi-step reasoning with visual and textual elements [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving)]. The primary source for information about PARROT-360V is an academic paper hosted on arXiv [[95](https://www.antekinc.com/as-4t360-400va-360v-transformer/)]. The title of the paper is "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[2](https://arxiv.org/html/2411.15201v1)]. The PARROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) on complex, sequential puzzles that mirror real-world challenges [[1](https://arxiv.org/abs/2411.15201)]. The PARROT-360V dataset includes 2,487 visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are sourced from jumbled puzzles [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)].The PARROT-360V benchmark is designed to evaluate Vision Language Models (VLMs) on complex, sequential puzzles that mirror real-world challenges [[1](https://arxiv.org/abs/2411.15201)]. The PARROT-360V dataset includes 2,487 visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are sourced from jumbled puzzles [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. The PARROT-360V benchmark is a novel evaluation tool for Vision Language Models (VLMs) that emphasizes complex, multi-step reasoning with visual and textual elements [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving)]. The primary source for information about PARROT-360V is an academic paper hosted on arXiv [[95](https://www.antekinc.com/as-4t360-400va-360v-transformer/)]. The title of the paper is "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[2](https://arxiv.org/html/2411.15201v1)].The PARROT-360V benchmark includes 2,487 visual puzzles specifically designed to evaluate VLMs on their capacity for complex visual reasoning [[52](https://www.cpubenchmark.net/graph_notes.html)]. These puzzles are sourced from jumbled puzzles [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark is a tool designed to evaluate the capabilities of Vision Language Models (VLMs) in complex visual reasoning [[37](https://dl.acm.org/doi/10.1609/aaai.v37i3.25450)]. The PARROT-360V benchmark dataset includes 2487 challenging visual puzzles [[21](https://idptools-parrot.readthedocs.io/en/stable/usage/basic_examples.html)]. The puzzles are jumbled to create the dataset [[61](https://www.researchgate.net/publication/339408787_PAROT_Translating_natural_language_to_SPARQL)]. The PARROT-360V benchmark features 2,487 challenging visual puzzles [[113](https://developers.google.com/earth-engine/guides/computation_benchmarks)]. The PARROT-360V benchmark is a novel evaluation tool for Vision Language Models (VLMs) that emphasizes complex, multi-step reasoning with visual and textual elements [[6](https://www.redblock.ai/blog/parrot-360v-elevating-vlm-evaluation-through-real-world-problem-solving)]. The primary source for information about PARROT-360V is an academic paper hosted on arXiv [[95](https://www.antekinc.com/as-4t360-400va-360v-transformer/)]. The title of the paper is "Beyond Visual Understanding: Introducing PARROT-360V for Vision Language Model Benchmarking" [[2](https://arxiv.org/html/2411.15201v1)].
✨  Done in 280.52s.